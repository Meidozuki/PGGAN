{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from glob import glob\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from myutils.ipynb\n",
      "importing Jupyter notebook from styleGAN_layers.ipynb\n"
     ]
    }
   ],
   "source": [
    "import ipynb_importer\n",
    "from myutils import make_anime_dataset,visualize_result,clear_imgs,train_time_log,set_memory_growth\n",
    "from styleGAN_layers import Dense,Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "jit: True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "\n",
    "os.environ['TF_XLA_FLAGS']='--tf_xla_enable_xla_devices --tf_xla_auto_jit=fusible --tf_xla_cpu_global_jit --tf_xla_always_defer_compilation=false --tf_xla_enable_lazy_compilation=true'\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "print('jit:',tf.config.optimizer.get_jit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_method='bilinear' #共3处，GT，G_block,Generator\n",
    "\n",
    "ckpt_dir=\"./checkpoints/PGGAN\"\n",
    "re_dir=\"./results/PGGAN\"\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "if not os.path.exists(re_dir):\n",
    "    os.makedirs(re_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_real_image(x,cur_res,alpha=1.0):\n",
    "    x=tf.image.resize(x,(cur_res,cur_res))\n",
    "    if (alpha >= 1.0) :\n",
    "        return x\n",
    "    else:\n",
    "        y=tf.image.resize(x,(cur_res//2,cur_res//2))\n",
    "        y=tf.image.resize(x,(cur_res,cur_res),method=upsample_method)\n",
    "        return lerp_clip(y,x,alpha)\n",
    "\n",
    "def get_ckpt_path(cur_res):\n",
    "    G_path=os.path.join(ckpt_dir,'generator{0}x{0}.h5'.format(cur_res))\n",
    "    D_path=os.path.join(ckpt_dir,'discriminator{0}x{0}.h5'.format(cur_res))\n",
    "    return D_path,G_path\n",
    "\n",
    "def get_train_steps(base_n=1000,increase_n=1000,target_res=64,batch_size=1):\n",
    "    res=4\n",
    "    re={}\n",
    "    while (res <= target_res):\n",
    "        re[res]=int(base_n+increase_n*np.floor(np.log2(res/4)))//batch_size\n",
    "        res*=2\n",
    "    return re\n",
    "    \n",
    "def prepare_model(resolution,G_before_D=False,load=False,same_res=False,compile_optimizer=False):\n",
    "    #functional API不用build\n",
    "    D=Discriminator(resolution)\n",
    "    G=Generator(resolution)\n",
    "    \n",
    "    if compile_optimizer is True:\n",
    "        global cur_lr,optimizer_name\n",
    "        d_op,g_op=prepare_optimizer(cur_lr,optimizer_name)\n",
    "        D.compile(d_op)\n",
    "        G.compile(g_op)\n",
    "        \n",
    "    if load is True:\n",
    "        if not same_res:\n",
    "            assert resolution > 4\n",
    "            resolution=resolution//2\n",
    "        D_path,G_path=get_ckpt_path(resolution)\n",
    "        D.load_weights(D_path,by_name=True)\n",
    "        G.load_weights(G_path,by_name=True)\n",
    "    \n",
    "    if G_before_D:\n",
    "        return G,D\n",
    "    else:\n",
    "        return D,G\n",
    "\n",
    "def prepare_optimizer(learning_rate,optimizer,beta1=0.,beta2=0.99):\n",
    "    if (type(learning_rate) is float):\n",
    "        d_lr=g_lr=learning_rate\n",
    "    else:\n",
    "        d_lr,g_lr=[learning_rate[0],learning_rate[1]]\n",
    "    print('d_learning_rate={:.3e},g_learning_rate={:.3e}'.format(d_lr,g_lr))\n",
    "    \n",
    "    if (str.lower(optimizer) == 'rmsprop'):\n",
    "        d_optimizer= tf.keras.optimizers.RMSprop(learning_rate=d_lr)\n",
    "        g_optimizer= tf.keras.optimizers.RMSprop(learning_rate=g_lr)\n",
    "    elif (str.lower(optimizer) == 'adam'):\n",
    "        d_optimizer= tf.keras.optimizers.Adam(learning_rate=d_lr,beta_1=beta1,beta_2=beta2)\n",
    "        g_optimizer= tf.keras.optimizers.Adam(learning_rate=g_lr,beta_1=beta1,beta_2=beta2)\n",
    "    assert d_optimizer is not None\n",
    "    return d_optimizer,g_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将layer替换成tf的resize\n",
    "def Generator(resolution=1024):\n",
    "    resolution_log2=int(np.log2(resolution))\n",
    "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
    "    \n",
    "    inputs=layers.Input((100,),name='GInput')\n",
    "    alpha=layers.Input((),batch_size=1,name='GAlpha')\n",
    "    \n",
    "    x=g_ConvBlock(2,name='g_block{0}x{0}'.format(4))(inputs)\n",
    "    image=toRGB(name='toRGB{0}x{0}'.format(4))(x)\n",
    "    \n",
    "    for i in range(3,resolution_log2+1):\n",
    "        cur_res=2**i\n",
    "        x=g_ConvBlock(i,name='g_block{0}x{0}'.format(cur_res))(x)\n",
    "        img=toRGB(name='toRGB{0}x{0}'.format(cur_res))(x)\n",
    "        \n",
    "        if (i == resolution_log2):\n",
    "            image=tf.image.resize(image,(cur_res,cur_res),method=upsample_method)\n",
    "#             image=layers.UpSampling2D(interpolation=upsample_method,name='upsample{}to{}'.format(cur_res//2,cur_res))(image)\n",
    "            image=lerp_clip(image,img,alpha)\n",
    "        else:\n",
    "            image=img\n",
    "            \n",
    "    model=tf.keras.Model(inputs=[inputs,alpha],outputs=image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(Generator(8),show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(resolution=1024):\n",
    "    resolution_log2=int(np.log2(resolution))\n",
    "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
    "    \n",
    "    inputs=layers.Input((resolution,resolution,3),name='DInput')\n",
    "    alpha=layers.Input((),batch_size=1,name='DAlpha')\n",
    "    \n",
    "    x=fromRGB(resolution_log2,name='fromRGB{0}x{0}'.format(resolution))(inputs)\n",
    "    for i in range(resolution_log2,2,-1):\n",
    "        cur_res=2**i\n",
    "        x=d_ConvBlock(i,name='d_block{0}x{0}'.format(cur_res))(x)\n",
    "        if (i == resolution_log2):\n",
    "            img=layers.AvgPool2D(name='downsample{}'.format(i))(inputs)\n",
    "            y=fromRGB(level=i-1,name='fromRGB{0}x{0}'.format(resolution//2))(img)\n",
    "            x=lerp_clip(y,x,alpha)\n",
    "    x=d_ConvBlock(2,name='d_block4x4')(x)\n",
    "    \n",
    "    model=tf.keras.Model(inputs=[inputs,alpha],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(Discriminator(8),show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class g_ConvBlock(layers.Layer):\n",
    "    def __init__(self,level,kernel_size=3,norm_latent=True,name=None):\n",
    "        super(g_ConvBlock,self).__init__(name=name)\n",
    "        \n",
    "        assert level >=2\n",
    "        self.level=level\n",
    "        self.norm_latent=norm_latent\n",
    "        \n",
    "        if level > 2:\n",
    "            self.upsample=layers.UpSampling2D(interpolation=upsample_method,name=name+'_upsample')\n",
    "            self.conv1=Conv2D(nf(level-1),kernel_size=kernel_size,strides=1,name=name+'_conv1')\n",
    "            self.conv2=Conv2D(nf(level-1),kernel_size=kernel_size,strides=1,name=name+'_conv2')\n",
    "        else:\n",
    "            self.fc=Dense(nf(1)*16,name=name+'_dense')\n",
    "            self.conv=Conv2D(nf(1),kernel_size=kernel_size,strides=1,name=name+'_conv')\n",
    "        self.PN=PixelNorm()\n",
    "            \n",
    "    def call(self,inputs,training=False):\n",
    "        if self.level > 2:\n",
    "            x=self.upsample(inputs)\n",
    "            x=self.PN(self.conv1(x))\n",
    "            x=self.PN(self.conv2(x))\n",
    "        else:\n",
    "            if self.norm_latent:\n",
    "                inputs=self.PN(inputs)\n",
    "            x=self.PN(self.fc(inputs))\n",
    "            x=tf.reshape(x,[-1,4,4,nf(1)])\n",
    "            x=self.PN(self.conv(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class toRGB(layers.Layer):\n",
    "    def __init__(self,filters=3,name=None):\n",
    "        super(toRGB,self).__init__(name=name)\n",
    "        \n",
    "        self.conv=Conv2D(filters=filters,kernel_size=1,strides=1,activation=None,name=name+'_conv')\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        x=self.conv(inputs)\n",
    "        return x\n",
    "    \n",
    "class d_ConvBlock(layers.Layer):\n",
    "    def __init__(self,level,kernel_size=3,mbstd_groups_size=4,features=1,name=None):\n",
    "        super(d_ConvBlock,self).__init__(name=name)\n",
    "        \n",
    "        assert level >=2\n",
    "        self.level=level\n",
    "        \n",
    "        if level > 2:\n",
    "            self.conv1=Conv2D(nf(level-1),kernel_size=kernel_size,strides=1,name=name+'_conv1')\n",
    "            self.conv2=Conv2D(nf(level-2),kernel_size=kernel_size,strides=1,name=name+'_conv2')\n",
    "            self.downsample=layers.AveragePooling2D(name=name+'_downsample')\n",
    "        else:\n",
    "            if mbstd_groups_size > 1:\n",
    "                self.mbstd=MinibatchStd(mbstd_groups_size,features,name=name+'_mbstd')\n",
    "            self.conv=Conv2D(nf(1),kernel_size=kernel_size,strides=1,name=name+'_conv')\n",
    "            self.flatten=layers.Flatten(name=name+'_flatten')\n",
    "            self.fc1=Dense(nf(0),name=name+'_dense1')\n",
    "            self.fc2=Dense(1,activation=None,name=name+'_dense2')\n",
    "    \n",
    "    def call(self,inputs,training=False):\n",
    "        if self.level > 2:\n",
    "            x=self.conv1(inputs)\n",
    "            #x=_blur2d(x)\n",
    "            x=self.conv2(x)\n",
    "            x=self.downsample(x)\n",
    "        else:\n",
    "            if self.mbstd is not None:\n",
    "                inputs=self.mbstd(inputs)\n",
    "            x=self.conv(inputs)\n",
    "            x=self.flatten(x)\n",
    "            x=self.fc1(x)\n",
    "            x=self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class fromRGB(layers.Layer):\n",
    "    def __init__(self,level,name=None):\n",
    "        super(fromRGB,self).__init__(name=name)\n",
    "        \n",
    "        self.conv=Conv2D(filters=nf(level-1),kernel_size=1,strides=1,name=name+'_conv')\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        x=self.conv(inputs)\n",
    "        return x\n",
    "\n",
    "class MinibatchStd(layers.Layer):\n",
    "    def __init__(self,group_size,num_new_features,**kargs):\n",
    "        super().__init__(**kargs)\n",
    "        self.group_size=group_size\n",
    "        self.num_new_features=num_new_features\n",
    "    \n",
    "    def call(self,x):\n",
    "        x=tf.transpose(x,perm=[0,3,1,2])# [NHWC]->[NCHW]\n",
    "        group_size=tf.minimum(self.group_size,tf.shape(x)[0])\n",
    "        s=x.shape\n",
    "        y=tf.reshape(x,\n",
    "                    [group_size,-1,self.num_new_features,s[1]//self.num_new_features,s[2],s[3]])\n",
    "        y=tf.cast(y,tf.float32)\n",
    "        y-=tf.reduce_mean(y,axis=0,keepdims=True)\n",
    "        y=tf.reduce_mean(tf.square(y),axis=0)\n",
    "        y=tf.sqrt(y+1e-8)\n",
    "        y=tf.reduce_mean(y,axis=[2,3,4],keepdims=True)\n",
    "        y=tf.reduce_mean(y,axis=[2])\n",
    "        y=tf.cast(y,x.dtype)\n",
    "        y=tf.tile(y,[self.group_size,1,s[2],s[3]])\n",
    "        x=tf.concat([x,y],axis=1)\n",
    "        x=tf.transpose(x,perm=[0,2,3,1])\n",
    "        return x\n",
    "    \n",
    "class PixelNorm(layers.Layer):\n",
    "    def __init__(self,**kargs):\n",
    "        super().__init__(**kargs)\n",
    "    \n",
    "    def call(self,x,epsilon=1e-8):\n",
    "        axis=3 if len(x.shape) > 2 else 1\n",
    "        #乘rsqrt比除以sqrt效率高\n",
    "        return x*tf.math.rsqrt(tf.reduce_mean(tf.square(x),axis=axis,keepdims=True)+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp_clip(a,b,t):\n",
    "    return a+(b-a)*tf.clip_by_value(t,0.0,1.0)\n",
    "\n",
    "def nf(stage, fmap_base=8192, fmap_decay=1.0, fmap_max=512): \n",
    "    return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def gradient_penalty(D,real,fake,alpha):\n",
    "    t=tf.random.uniform([real.shape[0],1,1,1])\n",
    "    t=tf.broadcast_to(t, real.shape)\n",
    "    interplate= t*real + (1-t)*fake\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([interplate])\n",
    "        d_interplate_logits=D([interplate,alpha])\n",
    "    grads=tape.gradient(d_interplate_logits,interplate)\n",
    "    \n",
    "    grads=tf.reshape(grads,[grads.shape[0], -1])\n",
    "    gp=tf.norm(grads,axis=1)\n",
    "    gp=tf.reduce_mean((gp-1)**2)\n",
    "    return gp\n",
    "\n",
    "# @tf.function\n",
    "def d_loss_fn(G,D,noise,batch_x,alpha):\n",
    "    fake_image= G([noise,alpha])\n",
    "    d_fake_logits= D([fake_image,alpha])\n",
    "    d_real_logits= D([batch_x,alpha])\n",
    "    \n",
    "#     t=K.random_uniform((batch_x.shape[0],1,1,1))\n",
    "#     t=tf.broadcast_to(t,batch_x.shape)\n",
    "#     interplate=t*batch_x + (1-t)*fake_image\n",
    "\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch([interplate])\n",
    "#         d_interplate_logits=D([interplate,alpha])\n",
    "#     grads=tape.gradient(d_interplate_logits,interplate)\n",
    "#     grads=tf.reshape(grads,[grads.shape[0],-1])\n",
    "#     gp=tf.norm(grads,axis=1)\n",
    "#     gp=tf.reduce_mean((grads-1.)**2)\n",
    "\n",
    "    gp=gradient_penalty(D,batch_x,fake_image,alpha)\n",
    "    W=tf.reduce_mean(d_fake_logits - d_real_logits)\n",
    "    loss=W + gp_lambda*gp\n",
    "\n",
    "    return loss,d_real_logits,W\n",
    "\n",
    "# @tf.function\n",
    "def g_loss_fn(G,D,noise,batch_x,alpha):\n",
    "    fake_image= G([noise,alpha])\n",
    "    d_fake_logits= D([fake_image,alpha])\n",
    "    loss=tf.reduce_mean(-d_fake_logits)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def D_train_step(G,D,x,alpha):\n",
    "    noise=K.random_normal((batch_size,z_dim))\n",
    "    with tf.GradientTape() as tape:\n",
    "        d_loss,real_logits,W= d_loss_fn(G,D,noise,x,alpha)\n",
    "#     grads = tape.gradient(d_loss, D.trainable_variables)\n",
    "#     D.optimizer.apply_gradients(zip(grads, D.trainable_variables))\n",
    "    D.optimizer.minimize(d_loss, D.trainable_variables,tape=tape)\n",
    "    return d_loss,tf.reduce_mean(real_logits),W\n",
    " \n",
    "# @tf.function\n",
    "def G_train_step(G,D,x,alpha):\n",
    "    noise=K.random_normal((batch_size,z_dim))\n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss= g_loss_fn(G,D,noise,x,alpha)\n",
    "#     grads = tape.gradient(g_loss, G.trainable_variables)\n",
    "#     G.optimizer.apply_gradients(zip(grads, G.trainable_variables))\n",
    "    G.optimizer.minimize(g_loss, G.trainable_variables,tape=tape)\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainScheduler:\n",
    "    '''\n",
    "    需要预先定义skpt_dir，在该文件夹下以txt的形式保存训练进度\n",
    "    会恢复cur_res,cur_lr,resume_step；D,G及其optimizer\n",
    "    '''\n",
    "    def __init__(self,resume=False):\n",
    "        global ckpt_dir\n",
    "        self.sch_path=os.path.join(ckpt_dir,'schedule.txt')\n",
    "        if not os.path.exists(self.sch_path):\n",
    "            with open(self.sch_path,'w') as f:\n",
    "                f.write('')\n",
    "        elif resume is True:\n",
    "            self.resume_train()\n",
    "    \n",
    "        \n",
    "    def pause_train(self):\n",
    "        global resume_step,step\n",
    "        try:\n",
    "            loc_step=resume_step+step\n",
    "        except NameError:\n",
    "            loc_step=step\n",
    "        f=open(self.sch_path,'r+')\n",
    "        f.truncate()\n",
    "        print('cur_res=%d' % cur_res,'step=%d' % loc_step,'cur_lr=%e' % cur_lr,sep='\\n',file=f)\n",
    "        f.close()\n",
    "        \n",
    "    \n",
    "    def resume_train(self,lower=False):\n",
    "        global cur_res,cur_lr,resume_step,D,G\n",
    "        \n",
    "        def get_digit_string(f):\n",
    "            s=f.readline()\n",
    "            print(s)\n",
    "            pos=s.find('=')+1\n",
    "            return s[pos:]\n",
    "\n",
    "        f=open(self.sch_path,'r+')\n",
    "        cur_res=int(get_digit_string(f))\n",
    "        resume_step=int(get_digit_string(f))\n",
    "        cur_lr=float(get_digit_string(f))\n",
    "        f.close()\n",
    "        \n",
    "        if lower is False:\n",
    "            D,G=prepare_model(cur_res,load=True,same_res=True,compile_optimizer=True)\n",
    "        else:\n",
    "            resume_step=99999\n",
    "            D,G=prepare_model(cur_res,load=True,same_res=False,compile_optimizer=True)\n",
    "            cur_res//=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read images of 51223\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#准备数据集\n",
    "input_size=64\n",
    "z_dim=100\n",
    "batch_size=4\n",
    "\n",
    "paths= glob(r'.\\faces\\*.jpg')\n",
    "print(\"read images of\",len(paths))\n",
    "dataset,size= make_anime_dataset(paths,batch_size,resize=(input_size,input_size),return_size=True)\n",
    "print(size)\n",
    "data_iter=iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_learning_rate=2.000e-04,g_learning_rate=2.000e-04\n",
      "{4: 5000, 8: 4000, 16: 3000, 32: 2000, 64: 1000}\n"
     ]
    }
   ],
   "source": [
    "learning_rate=2e-4\n",
    "cur_lr=learning_rate\n",
    "optimizer_name='adam'\n",
    "\n",
    "cur_res=4\n",
    "gp_lambda=8.\n",
    "\n",
    "shift_imgs=0.5e4\n",
    "shift_step=int(np.ceil(shift_imgs/batch_size/1e3))*1000\n",
    "alpha_increase=1.0/shift_step\n",
    "\n",
    "save_step=100\n",
    "display_step=50\n",
    "\n",
    "alpha=tf.Variable(1.0,trainable=False)\n",
    "D,G=prepare_model(4,compile_optimizer=True)\n",
    "\n",
    "train_schedule=get_train_steps(base_n=2e4,increase_n=-4e3,batch_size=batch_size)\n",
    "print(train_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logdir=r'D:\\jupyter\\checkpoints\\PGGAN\\profiler'\n",
    "\n",
    "# writer=tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# with writer.as_default():\n",
    "#     tf.profiler.experimental.start(logdir)\n",
    "    \n",
    "#     dataset= make_anime_dataset(paths,batch_size,resize=(input_size,input_size),return_size=False)\n",
    "#     data_iter=iter(dataset)\n",
    "#     x=process_real_image(next(data_iter)[0],cur_res,alpha)\n",
    "#     try:\n",
    "#         for i in range(5):\n",
    "# #             with tf.profiler.experimental.Trace('train',\n",
    "# #                                                 step_num=i, _r=1):\n",
    "#             loss,_,_=D_train_step(G,D,x,alpha)\n",
    "#             tf.summary.scalar(\n",
    "#                     'Train/Loss', data=loss, step=i)\n",
    "#     except Exception as e:\n",
    "#         tf.profiler.experimental.stop()\n",
    "#         raise e\n",
    "#     else:\n",
    "#         tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume_step not existing\n",
      "0\n",
      "cur_res=4\n"
     ]
    }
   ],
   "source": [
    "if 0:\n",
    "    clear_imgs(re_dir)\n",
    "\n",
    "train_sch=TrainScheduler()\n",
    "\n",
    "if 0:\n",
    "    train_sch.resume_train(lower=False)\n",
    "else:\n",
    "    try:\n",
    "        alpha=alpha_increase*resume_step\n",
    "    except NameError:\n",
    "        print('resume_step not existing')\n",
    "    finally:\n",
    "        resume_step=0\n",
    "print(resume_step)\n",
    "print('cur_res=%d' % cur_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0000, d_loss= 3.8013458252, g_loss= 0.3677308261, d_real= -0.1804591417, EM_dist= -0.0733585060\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0050, d_loss= -0.8568097949, g_loss= 0.8990772963, d_real= -0.0841032267, EM_dist= -0.9792104959\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMWElEQVR4nO3dfYxcdb3H8c/nbot9oNsVpU2l9QI+ND5TsqkxTTRSr7coKcZgbI0YUVONwYBPBJSYq/6j0RD4w9T0VrxECqgVDCI+ENCgUSt9Ulu2mNKgLAVb1FraQmvL9/6xU7O6u+6Z2XN+M/3m/UoadvZMzvczKZ+emTMz5+eIEIA8/qPbAQDUi1IDyVBqIBlKDSRDqYFkpjWx05n9s2PuvIEmdj3Ggr4zisyRpP1/HSo2S5Ke2/fKcsNmlHsXZOe0p4vNesXh3cVmSdKOF8wtM+iRI4onj3q8TY2Ueu68Ab3nyx9sYtdjXDP3XUXmSNL/fmuw2CxJevvAfeWGLT5abNSr5+8oNuu7m1YWmyVJL/7M8jKDlt474SaefgPJUGogGUoNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lUKrXtFbYfsr3b9tVNhwLQuUlLbbtP0lckXSjp5ZJW235508EAdKbKkXqppN0RsScijkm6TdLFzcYC0KkqpT5L0qOjbg+3fvdPbK+xvdn25qcPHq4rH4A2VSn1eF/vGvM9vYhYFxGDETE4s3/21JMB6EiVUg9LWjTq9kJJe5uJA2CqqpT6AUkvsX2O7dMkrZJ0Z7OxAHRq0oskRMRx25dL+pGkPkk3RsTOxpMB6EilK59ExN2S7m44C4Aa8IkyIBlKDSRDqYFkKDWQDKUGkqHUQDKUGkimkRU6ztw3S2u+sqSJXY/xjY0zi8yRpPk3rSk2S5JWvKbcCh1fXL6p2KyP/+6SYrNuuXNesVmStHFfmTlX/XHibRypgWQoNZAMpQaSodRAMpQaSIZSA8lQaiAZSg0kQ6mBZCg1kEyVFTputL3P9o4SgQBMTZUj9f9JWtFwDgA1mbTUEXG/pL8UyAKgBrW9ph697M5f/v63unYLoE21lXr0sjtnTJ9b124BtImz30AylBpIpspbWrdK+qWkxbaHbb+/+VgAOlVlLa3VJYIAqAdPv4FkKDWQDKUGkqHUQDKUGkiGUgPJUGogmUaW3dkz8zGtetW1Tex6jB273lBkjiRN+8D3i82SpLve97Jisy6f8c5is46+YFGxWTMuvLXYLEm6fvfSInOmHX/thNs4UgPJUGogGUoNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiCZKtcoW2T7J7aHbO+0fUWJYAA6U+Wz38clfTwittqeI2mL7Xsi4sGGswHoQJVldx6PiK2tn5+SNCTprKaDAehMW9/Ssn22pCWSNo2zbY2kNZJ02pzpdWQD0IHKJ8psny7pO5KujIiD/7p99LI702Y28o1OABVUKrXt6Rop9IaIuL3ZSACmosrZb0v6mqShiLiu+UgApqLKkXqZpEslXWB7e+vPWxrOBaBDVZbd+bkkF8gCoAZ8ogxIhlIDyVBqIBlKDSRDqYFkKDWQDKUGkqHUQDKNfPNiYPYLtfL8tU3seoxfXfJAkTmS9Nh77io2S5JuvvfeYrNe+8Q3i816x9H+YrN2nvffxWZJ0rz3Ly4yZ9qDwxNu40gNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiAZSg0kU+XCgzNs/9r2b1rL7ny2RDAAnanyMdGjki6IiEOtSwX/3PYPIuJXDWcD0IEqFx4MSYdaN6e3/kSToQB0rurF/Ptsb5e0T9I9ETHusju2N9vefPjggXpTAqisUqkj4kREnCdpoaSltl85zn3+sezO7P6BelMCqKyts98RcUDSTyWtaCIMgKmrcvb7TNsDrZ9nSnqTpF0N5wLQoSpnvxdIusl2n0b+EfhWRJS9WgCAyqqc/f6tRtakBnAK4BNlQDKUGkiGUgPJUGogGUoNJEOpgWQoNZAMpQaSaWTZnXnH9+vKv5ZZdmfPVz9cZI4kLfrtgWKzJOmZT7672KzLPnR1sVnHzy33uFbPvrTYLEn62bWfKDLnmb1fmHAbR2ogGUoNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiAZSg0kU7nUrQv6b7PNRQeBHtbOkfoKSUNNBQFQj6rL7iyU9FZJ65uNA2Cqqh6pr5d0laRnJ7rD6LW0/nzoaB3ZAHSgygodF0naFxFb/t39Rq+l9bzTn1NbQADtqXKkXiZppe1HJN0m6QLbNzeaCkDHJi11RFwTEQsj4mxJqyTdFxHlvuUOoC28Tw0k09bljCLipxpZyhZAj+JIDSRDqYFkKDWQDKUGkqHUQDKUGkiGUgPJNLLszsOPD+htn1vZxK7H+OJb3lhkjiQdXdBXbJYkfe9V/cVmPbH/88VmXTPn4WKzZp9Rdtmd6R+9r8gcb3tqwm0cqYFkKDWQDKUGkqHUQDKUGkiGUgPJUGogGUoNJEOpgWQoNZBMpY+Jtq4k+pSkE5KOR8Rgk6EAdK6dz36/MSKebCwJgFrw9BtIpmqpQ9KPbW+xvWa8O4xedufYswfrSwigLVWffi+LiL2250m6x/auiLh/9B0iYp2kdZLUP/1FUXNOABVVOlJHxN7Wf/dJukPS0iZDAehclQXyZtuec/JnSW+WtKPpYAA6U+Xp93xJd9g+ef9bIuKHjaYC0LFJSx0ReyS9pkAWADXgLS0gGUoNJEOpgWQoNZAMpQaSodRAMpQaSKaRZXdmzj+iV1+xrYldj/H5+V8tMkeSfu03FJslSff/eVWxWec8c7TYrKXfP1Rs1pdOLCo2S5IO3PDSInOOH5q4XxypgWQoNZAMpQaSodRAMpQaSIZSA8lQaiAZSg0kQ6mBZCg1kEylUtsesL3R9i7bQ7Zf13QwAJ2p+tnvGyT9MCIusX2apFkNZgIwBZOW2na/pNdLeq8kRcQxSceajQWgU1Wefp8rab+kr9veZnt96/rf/2T0sjtPHz5Se1AA1VQp9TRJ50taGxFLJB2WdPW/3iki1kXEYEQMzpzNs3OgW6qUeljScERsat3eqJGSA+hBk5Y6Ip6Q9Kjtxa1fLZf0YKOpAHSs6tnvj0ja0DrzvUfSZc1FAjAVlUodEdslDTYbBUAd+EQZkAylBpKh1EAylBpIhlIDyVBqIBlKDSRDqYFkGllL67kn+vSOAwNN7HqMXf/zcJE5knTD/g3FZknSL9ZeV2zW4y63ltaSq/5UbNZF154oNkuS7lk7p8icGZ/um3AbR2ogGUoNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiCZSUtte7Ht7aP+HLR9ZYFsADow6cdEI+IhSedJku0+SY9JuqPZWAA61e7T7+WSHo6IPzQRBsDUtVvqVZJuHW/D6GV3Dhw5PPVkADpSudSta36vlPTt8baPXnZnYNaYpbYAFNLOkfpCSVsjotz35gC0rZ1Sr9YET70B9I5KpbY9S9J/Sbq92TgApqrqsjtHJD2v4SwAasAnyoBkKDWQDKUGkqHUQDKUGkiGUgPJUGogGUoNJOOIqH+n9n5J7X498/mSnqw9TG/I+th4XN3znxFx5ngbGil1J2xvjojBbudoQtbHxuPqTTz9BpKh1EAyvVTqdd0O0KCsj43H1YN65jU1gHr00pEaQA0oNZBMT5Ta9grbD9nebfvqbuepg+1Ftn9ie8j2TttXdDtTnWz32d5m+65uZ6mT7QHbG23vav3dva7bmdrV9dfUrQUCfq+RyyUNS3pA0uqIeLCrwabI9gJJCyJiq+05krZIetup/rhOsv0xSYOS+iPiom7nqYvtmyT9LCLWt66gOysiDnQ5Vlt64Ui9VNLuiNgTEcck3Sbp4i5nmrKIeDwitrZ+fkrSkKSzupuqHrYXSnqrpPXdzlIn2/2SXi/pa5IUEcdOtUJLvVHqsyQ9Our2sJL8z3+S7bMlLZG0qctR6nK9pKskPdvlHHU7V9J+SV9vvbRYb/uUu4h9L5Ta4/wuzftstk+X9B1JV0bEwW7nmSrbF0naFxFbup2lAdMknS9pbUQskXRY0il3jqcXSj0sadGo2wsl7e1SllrZnq6RQm+IiCyXV14maaXtRzTyUukC2zd3N1JthiUNR8TJZ1QbNVLyU0ovlPoBSS+xfU7rxMQqSXd2OdOU2bZGXpsNRcR13c5Tl4i4JiIWRsTZGvm7ui8i3t3lWLWIiCckPWp7cetXyyWdcic2K133u0kRcdz25ZJ+JKlP0o0RsbPLseqwTNKlkn5ne3vrd5+KiLu7FwkVfETShtYBZo+ky7qcp21df0sLQL164ek3gBpRaiAZSg0kQ6mBZCg1kAylBpKh1EAy/w+bRuBZUzLPswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0073/5000 73 steps in 9.227s, 126.4ms per\n",
      "Interrupted\n",
      "Train End\n"
     ]
    }
   ],
   "source": [
    "while (cur_res <= input_size):\n",
    "    if (cur_res == 4):\n",
    "        total_step=train_schedule[4]\n",
    "    else:\n",
    "        total_step=shift_step+train_schedule[cur_res]\n",
    "        \n",
    "    start_time=time.time()\n",
    "    total_step-=resume_step\n",
    "    alpha=tf.Variable(alpha_increase*resume_step,trainable=False,name='alpha')\n",
    "    \n",
    "    try:\n",
    "        noise=K.random_normal((batch_size,z_dim))\n",
    "        for step in range(total_step+1):\n",
    "            #准备数据\n",
    "            print(\"\\r%04d/%04d \" % (step,total_step),end='')\n",
    "            alpha.assign_add(alpha_increase)\n",
    "            x=next(data_iter)[0]\n",
    "            x=process_real_image(x,cur_res,alpha)\n",
    "\n",
    "            #训练\n",
    "            d_loss,d_real,W = D_train_step(G,D,x,alpha)\n",
    "            g_loss = G_train_step(G,D,x,alpha)\n",
    "\n",
    "            #可视化与保存\n",
    "            if step%display_step == 0 :\n",
    "                print(\"\\rstep= %04d, d_loss= %.10f, g_loss= %.10f, d_real= %.10f, EM_dist= %.10f\"\n",
    "                          % (step,float(d_loss),float(g_loss),float(d_real),W))\n",
    "                img_path=os.path.join(re_dir,\"PGGAN{0}x{0}_{1:04d}.jpg\".format(cur_res,step))\n",
    "                visualize_result(G,[noise,alpha],save_path=img_path,save=True,rewind=False)\n",
    "\n",
    "                if (step%save_step == 0 and step != 0):\n",
    "                    #保存\n",
    "                    D_path,G_path=get_ckpt_path(cur_res)\n",
    "                    D.save_weights(D_path)\n",
    "                    G.save_weights(G_path)\n",
    "\n",
    "\n",
    "        if (cur_res*2 > input_size): break\n",
    "\n",
    "        print('change resolution from %d to %d' % (cur_res,cur_res*2))\n",
    "        D_path,G_path=get_ckpt_path(cur_res)\n",
    "        D.save_weights(D_path)\n",
    "        G.save_weights(G_path)\n",
    "        train_time_log(time.time()-start_time,total_step)\n",
    "\n",
    "        resume_step=0\n",
    "        alpha.assign(0.0)\n",
    "        cur_res*=2\n",
    "        D,G=prepare_model(cur_res,load=True,compile_optimizer=True)\n",
    "        visualize_result(G,[noise,alpha], save=False,rewind=True)\n",
    "        train_time_log(time.time()-start_time,total_step)\n",
    "        print('start training at {0}x{0}'.format(cur_res))\n",
    "        print(\"Current learning rate=%.3e\" % (cur_lr))\n",
    "    except KeyboardInterrupt:\n",
    "        train_sch.pause_train()\n",
    "        train_time_log(time.time()-start_time,step)\n",
    "        print(\"Interrupted\")\n",
    "        break\n",
    "            \n",
    "print(\"Train End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
